{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq.gSCAN_dataset import GroundedScanDataset\n",
    "from seq2seq.model import Model\n",
    "from seq2seq.rollout import Rollout\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import inspect\n",
    "import numpy as np\n",
    "device = torch.device(type='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = GroundedScanDataset(\"gSCAN_data/data/compositional_splits/dataset.txt\", \"gSCAN_data/data/compositional_splits/\", split=\"train\", \n",
    "                                        input_vocabulary_file=\"training_input_vocab.txt\", \n",
    "                                        target_vocabulary_file=\"training_target_vocab.txt\", \n",
    "                                        generate_vocabulary=False, k=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = GroundedScanDataset(\"gSCAN_data/data/compositional_splits/dataset.txt\", \"gSCAN_data/data/compositional_splits/\", split=\"test\", \n",
    "                                        input_vocabulary_file=\"training_input_vocab.txt\", \n",
    "                                        target_vocabulary_file=\"training_target_vocab.txt\", \n",
    "                                        generate_vocabulary=False, k=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = training_set.dataset.get_examples_with_image(\"train\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, e in enumerate(example):\n",
    "    print(e)\n",
    "    input_commands = e[\"input_command\"]\n",
    "    target_commands = e[\"target_command\"]\n",
    "    situation_image = e[\"situation_image\"]\n",
    "    plt.imshow(situation_image[:,:,3])\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = testing_set.dataset.get_examples_with_image(\"test\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, e in enumerate(test_example):\n",
    "    print(e)\n",
    "    input_commands = e[\"input_command\"]\n",
    "    target_commands = e[\"target_command\"]\n",
    "    situation_image = e[\"situation_image\"]\n",
    "    plt.imshow(situation_image[:,:,3])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.read_dataset(max_examples=100,\n",
    "                              simple_situation_representation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {'data_path': 'gSCAN_data/data/compositional_splits/dataset.txt', 'data_directory': 'gSCAN_data/data/compositional_splits/', 'generate_vocabularies': False, 'input_vocab_path': 'training_input_vocab.txt', 'target_vocab_path': 'training_target_vocab.txt', 'embedding_dimension': 25, 'num_encoder_layers': 1, 'encoder_dropout_p': 0.3, 'encoder_bidirectional': True, 'training_batch_size': 50, 'test_batch_size': 1, 'max_decoding_steps': 30, 'num_decoder_layers': 1, 'decoder_dropout_p': 0.3, 'cnn_kernel_size': 7, 'cnn_dropout_p': 0.1, 'cnn_hidden_num_channels': 50, 'simple_situation_representation': True, 'decoder_hidden_size': 100, 'encoder_hidden_size': 100, 'learning_rate': 0.001, 'adam_beta_1': 0.9, 'adam_beta_2': 0.999, 'resume_from_file': '', 'max_training_iterations': 200000, 'output_directory': 'models', 'print_every': 100, 'evaluate_every': 1000, 'conditional_attention': True, 'auxiliary_task': False, 'weight_target_loss': 0.3, 'attention_type': 'bahdanau', 'k': 0, 'max_training_examples': None, 'seed': 42, 'kwargs': {'mode': 'train', 'split': 'test', 'max_testing_examples': None, 'splits': 'test', 'output_file_name': 'predict.json'}, 'device': device, 'lr_decay': 0.9, 'lr_decay_steps': 20000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chang/anaconda3/envs/gsCAN/lib/python3.8/site-packages/torch/nn/modules/rnn.py:47: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# model = Model(input_vocabulary_size=training_set.input_vocabulary_size,\n",
    "#                   target_vocabulary_size=training_set.target_vocabulary_size,\n",
    "#                   num_cnn_channels=training_set.image_channels,\n",
    "#                   input_padding_idx=training_set.input_vocabulary.pad_idx,\n",
    "#                   target_pad_idx=training_set.target_vocabulary.pad_idx,\n",
    "#                   target_eos_idx=training_set.target_vocabulary.eos_idx,\n",
    "#                   embedding_dimension=25, encoder_hidden_size=100, num_encoder_layers=1,\n",
    "#                   encoder_dropout_p=0.3, encoder_bidirectional=True, num_decoder_layers=1,\n",
    "#                   decoder_dropout_p=0.3, decoder_hidden_size=100, cnn_kernel_size=7, cnn_dropout_p=0.1,\n",
    "#                   cnn_hidden_num_channels=50, output_directory=\"models\", conditional_attention=True, auxiliary_task=False,\n",
    "#                   simple_situation_representation=True, attention_type=\"bahdanau\")\n",
    "model = Model(input_vocabulary_size=training_set.input_vocabulary_size,\n",
    "                  target_vocabulary_size=training_set.target_vocabulary_size,\n",
    "                  num_cnn_channels=training_set.image_channels,\n",
    "                  input_padding_idx=training_set.input_vocabulary.pad_idx,\n",
    "                  target_pad_idx=training_set.target_vocabulary.pad_idx,\n",
    "                  target_eos_idx=training_set.target_vocabulary.eos_idx,\n",
    "                  **cfg)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (situation_encoder): ConvolutionalNet(\n",
       "    (conv_1): Conv2d(16, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_2): Conv2d(16, 50, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (conv_3): Conv2d(16, 50, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (relu): ReLU()\n",
       "    (layers): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (visual_attention): Attention(\n",
       "    (key_layer): Linear(in_features=150, out_features=100, bias=False)\n",
       "    (query_layer): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (energy_layer): Linear(in_features=100, out_features=1, bias=False)\n",
       "  )\n",
       "  (encoder): EncoderRNN(\n",
       "    EncoderRNN\n",
       "     bidirectional=True \n",
       "     num_layers=1\n",
       "     hidden_size=100\n",
       "     dropout=0.3\n",
       "     n_input_symbols=21\n",
       "    \n",
       "    (embedding): Embedding(21, 25, padding_idx=0)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (lstm): LSTM(25, 100, dropout=0.3, bidirectional=True)\n",
       "  )\n",
       "  (enc_hidden_to_dec_hidden): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (textual_attention): Attention(\n",
       "    (key_layer): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (query_layer): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (energy_layer): Linear(in_features=100, out_features=1, bias=False)\n",
       "  )\n",
       "  (attention_decoder): BahdanauAttentionDecoderRNN(\n",
       "    AttentionDecoderRNN\n",
       "     num_layers=1\n",
       "     hidden_size=100\n",
       "     dropout=0.3\n",
       "     num_output_symbols=9\n",
       "    \n",
       "    (queries_to_keys): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (embedding): Embedding(9, 100, padding_idx=0)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (lstm): LSTM(300, 100, dropout=0.3)\n",
       "    (textual_attention): Attention(\n",
       "      (key_layer): Linear(in_features=100, out_features=100, bias=False)\n",
       "      (query_layer): Linear(in_features=100, out_features=100, bias=False)\n",
       "      (energy_layer): Linear(in_features=100, out_features=1, bias=False)\n",
       "    )\n",
       "    (visual_attention): Attention(\n",
       "      (key_layer): Linear(in_features=150, out_features=100, bias=False)\n",
       "      (query_layer): Linear(in_features=100, out_features=100, bias=False)\n",
       "      (energy_layer): Linear(in_features=100, out_features=1, bias=False)\n",
       "    )\n",
       "    (output_to_hidden): Linear(in_features=400, out_features=100, bias=False)\n",
       "    (hidden_to_output): Linear(in_features=100, out_features=9, bias=False)\n",
       "  )\n",
       "  (loss_criterion): NLLLoss()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = Rollout(model, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.1977, -2.2715, -2.2845, -2.3473, -1.8754, -2.3150, -2.4746,\n",
      "          -2.3151, -1.8752],\n",
      "         [-2.1626, -2.3288, -1.8263, -2.6755, -2.6097, -2.1257, -2.1233,\n",
      "          -2.2709, -1.9525],\n",
      "         [-2.0654, -2.4855, -2.1612, -2.2177, -2.3129, -2.1729, -2.1947,\n",
      "          -2.1692, -2.0604],\n",
      "         [-2.0411, -2.1134, -2.2031, -1.9930, -2.3282, -2.2059, -2.5773,\n",
      "          -2.1337, -2.2972],\n",
      "         [-2.1747, -2.2630, -2.2495, -1.9562, -2.1982, -2.4407, -2.1477,\n",
      "          -2.1214, -2.2951],\n",
      "         [-2.1939, -2.1876, -2.1612, -2.2024, -2.2294, -2.2020, -2.2232,\n",
      "          -2.1877, -2.1893],\n",
      "         [-2.1901, -2.1916, -2.1687, -2.2068, -2.2194, -2.2044, -2.2231,\n",
      "          -2.1827, -2.1896],\n",
      "         [-2.1877, -2.1950, -2.1716, -2.2082, -2.2146, -2.2051, -2.2222,\n",
      "          -2.1817, -2.1900],\n",
      "         [-2.1862, -2.1973, -2.1727, -2.2085, -2.2124, -2.2052, -2.2213,\n",
      "          -2.1820, -2.1905],\n",
      "         [-2.1852, -2.1987, -2.1731, -2.2084, -2.2114, -2.2050, -2.2205,\n",
      "          -2.1827, -2.1909],\n",
      "         [-2.1845, -2.1996, -2.1733, -2.2082, -2.2111, -2.2048, -2.2201,\n",
      "          -2.1832, -2.1913]],\n",
      "\n",
      "        [[-2.3313, -2.2979, -2.1957, -2.2408, -1.7677, -2.4883, -2.1049,\n",
      "          -2.3621, -2.1640],\n",
      "         [-2.3672, -2.2226, -1.7833, -2.3656, -2.4417, -2.2564, -2.0950,\n",
      "          -2.4616, -1.9962],\n",
      "         [-2.2517, -2.4163, -2.3094, -2.1908, -2.3275, -2.3143, -2.3369,\n",
      "          -1.7549, -2.0522],\n",
      "         [-1.9964, -1.9324, -2.3767, -1.7577, -2.4090, -2.3915, -2.4704,\n",
      "          -2.3238, -2.4053],\n",
      "         [-2.0288, -2.5720, -2.2069, -2.1472, -2.2216, -2.1694, -2.1199,\n",
      "          -2.0889, -2.3156],\n",
      "         [-2.0664, -1.8894, -2.2778, -1.8661, -2.5174, -2.2625, -2.5961,\n",
      "          -2.2067, -2.3480],\n",
      "         [-2.3024, -2.1460, -2.4338, -1.9428, -2.3775, -2.3382, -2.3445,\n",
      "          -1.8443, -2.2191],\n",
      "         [-2.1866, -2.1854, -2.1629, -2.2063, -2.2296, -2.1936, -2.2239,\n",
      "          -2.1904, -2.1980],\n",
      "         [-2.1849, -2.1887, -2.1728, -2.2079, -2.2225, -2.1971, -2.2193,\n",
      "          -2.1866, -2.1962],\n",
      "         [-2.1842, -2.1922, -2.1774, -2.2087, -2.2183, -2.1992, -2.2161,\n",
      "          -2.1853, -2.1946],\n",
      "         [-2.1837, -2.1947, -2.1796, -2.2091, -2.2159, -2.2004, -2.2142,\n",
      "          -2.1848, -2.1934]],\n",
      "\n",
      "        [[-2.0914, -2.0978, -2.3468, -2.3305, -1.9999, -2.4370, -2.4507,\n",
      "          -2.4238, -1.8125],\n",
      "         [-2.1617, -2.4600, -2.0058, -2.3693, -2.5028, -2.0855, -1.9839,\n",
      "          -2.3948, -1.9913],\n",
      "         [-2.1816, -2.4941, -2.3181, -2.2547, -2.3180, -2.0610, -2.1825,\n",
      "          -1.9649, -2.0997],\n",
      "         [-1.9204, -1.8442, -2.3305, -2.0816, -2.5180, -2.3192, -2.6563,\n",
      "          -2.0781, -2.3129],\n",
      "         [-2.0806, -2.5706, -2.3170, -1.9689, -2.2672, -2.0015, -2.2844,\n",
      "          -2.1509, -2.2679],\n",
      "         [-2.0766, -1.8601, -2.2703, -1.7726, -2.5920, -2.2775, -2.5939,\n",
      "          -2.3084, -2.3618],\n",
      "         [-2.2829, -2.1693, -2.2641, -2.0111, -2.1152, -2.2844, -2.5404,\n",
      "          -1.9144, -2.3302],\n",
      "         [-2.1998, -2.1847, -2.1724, -2.1956, -2.2207, -2.1938, -2.2201,\n",
      "          -2.1854, -2.2036],\n",
      "         [-2.1936, -2.1903, -2.1748, -2.2015, -2.2177, -2.1966, -2.2195,\n",
      "          -2.1798, -2.2022],\n",
      "         [-2.1903, -2.1937, -2.1752, -2.2050, -2.2157, -2.1981, -2.2178,\n",
      "          -2.1789, -2.2012],\n",
      "         [-2.1884, -2.1956, -2.1752, -2.2070, -2.2144, -2.1987, -2.2163,\n",
      "          -2.1797, -2.2005]],\n",
      "\n",
      "        [[-2.0856, -2.3231, -2.2355, -2.2427, -1.8204, -2.3102, -2.2051,\n",
      "          -2.5856, -2.1380],\n",
      "         [-2.0671, -2.3271, -2.0452, -2.5571, -2.6154, -2.1475, -2.0604,\n",
      "          -2.0740, -2.0717],\n",
      "         [-2.2112, -2.3827, -2.3792, -1.8500, -2.4641, -2.2404, -2.3383,\n",
      "          -1.9397, -2.1497],\n",
      "         [-2.1305, -1.8297, -2.2132, -1.9302, -2.3059, -2.3661, -2.6655,\n",
      "          -2.2690, -2.3045],\n",
      "         [-2.2395, -2.2355, -2.1841, -2.2155, -2.1492, -2.1771, -2.2050,\n",
      "          -2.2402, -2.1352],\n",
      "         [-2.1904, -1.9764, -2.1611, -2.1230, -2.3991, -2.2359, -2.2391,\n",
      "          -2.3242, -2.1842],\n",
      "         [-2.3173, -2.1833, -2.3448, -1.9391, -2.4325, -2.4870, -2.4674,\n",
      "          -1.6709, -2.2515],\n",
      "         [-2.1995, -2.1759, -2.1720, -2.2123, -2.2309, -2.2096, -2.2201,\n",
      "          -2.1576, -2.1994],\n",
      "         [-2.1910, -2.1830, -2.1783, -2.2124, -2.2240, -2.2090, -2.2187,\n",
      "          -2.1646, -2.1957],\n",
      "         [-2.1865, -2.1887, -2.1820, -2.2115, -2.2191, -2.2078, -2.2172,\n",
      "          -2.1692, -2.1943],\n",
      "         [-2.1842, -2.1924, -2.1842, -2.2106, -2.2160, -2.2066, -2.2162,\n",
      "          -2.1720, -2.1940]],\n",
      "\n",
      "        [[-1.9050, -2.0662, -2.3046, -2.4103, -2.2327, -2.2769, -2.4553,\n",
      "          -2.2997, -1.9735],\n",
      "         [-2.1140, -2.2803, -1.9536, -2.5387, -2.4201, -2.1927, -2.3702,\n",
      "          -2.2882, -1.8273],\n",
      "         [-2.1511, -2.3585, -2.3848, -1.9596, -2.2790, -2.1034, -2.2941,\n",
      "          -2.2307, -2.0929],\n",
      "         [-2.0264, -1.9871, -2.2862, -1.9302, -2.5116, -2.2204, -2.4419,\n",
      "          -2.2531, -2.2774],\n",
      "         [-2.2256, -2.3714, -2.2809, -2.1121, -2.3555, -2.2612, -2.1745,\n",
      "          -2.1017, -1.9627],\n",
      "         [-2.0382, -2.1037, -2.3313, -1.7489, -2.5466, -2.2634, -2.4405,\n",
      "          -2.2618, -2.2731],\n",
      "         [-2.0111, -2.4161, -2.3838, -2.1718, -2.3845, -2.1141, -2.2380,\n",
      "          -1.9265, -2.2487],\n",
      "         [-2.1979, -1.7959, -2.1511, -1.9910, -2.3761, -2.3515, -2.5449,\n",
      "          -2.2859, -2.2849],\n",
      "         [-2.2624, -2.2538, -2.3517, -2.1574, -2.0504, -2.4791, -2.2376,\n",
      "          -1.8269, -2.3032],\n",
      "         [-2.1863, -2.1876, -2.1600, -2.2105, -2.2544, -2.2006, -2.2233,\n",
      "          -2.1607, -2.1951],\n",
      "         [-2.1827, -2.1915, -2.1660, -2.2111, -2.2410, -2.2022, -2.2244,\n",
      "          -2.1652, -2.1935]],\n",
      "\n",
      "        [[-2.3053, -2.1764, -2.2983, -2.2694, -1.9635, -2.3264, -2.1732,\n",
      "          -2.3514, -1.9954],\n",
      "         [-2.2590, -2.6313, -1.7939, -2.1924, -2.3908, -2.4371, -2.1796,\n",
      "          -2.2261, -1.9269],\n",
      "         [-2.2777, -2.4350, -2.4384, -2.2070, -2.1784, -2.2212, -2.0403,\n",
      "          -1.8293, -2.2992],\n",
      "         [-2.0882, -1.9648, -2.2169, -1.9148, -2.3900, -2.4141, -2.4158,\n",
      "          -2.3732, -2.1538],\n",
      "         [-2.3214, -2.4154, -2.2944, -2.1595, -2.2604, -2.1441, -2.1199,\n",
      "          -2.0303, -2.0915],\n",
      "         [-2.0432, -1.9644, -2.4460, -1.9553, -2.4263, -2.0337, -2.5620,\n",
      "          -2.2080, -2.3466],\n",
      "         [-2.3865, -2.2898, -2.2852, -2.1441, -2.3900, -2.2464, -2.2227,\n",
      "          -1.8955, -2.0260],\n",
      "         [-2.1698, -2.0299, -2.0539, -2.0391, -2.2117, -2.5465, -2.4205,\n",
      "          -2.0909, -2.3460],\n",
      "         [-2.4095, -2.2563, -2.1226, -1.6672, -2.3884, -2.3111, -2.3912,\n",
      "          -2.1583, -2.3134],\n",
      "         [-2.2061, -2.1816, -2.1861, -2.1959, -2.2276, -2.2020, -2.2112,\n",
      "          -2.1813, -2.1843],\n",
      "         [-2.1946, -2.1882, -2.1855, -2.2052, -2.2189, -2.2031, -2.2115,\n",
      "          -2.1823, -2.1863]],\n",
      "\n",
      "        [[-2.1771, -2.0045, -2.3216, -2.5446, -1.8729, -2.2648, -2.2745,\n",
      "          -2.4643, -2.0416],\n",
      "         [-2.1747, -2.3198, -1.8418, -2.6111, -2.5639, -2.1126, -2.2458,\n",
      "          -2.0776, -2.0629],\n",
      "         [-2.1838, -2.5683, -2.4496, -1.9506, -2.1445, -2.2427, -2.1098,\n",
      "          -1.9147, -2.4052],\n",
      "         [-2.0132, -2.2354, -2.2339, -2.0783, -2.2134, -2.2462, -2.2210,\n",
      "          -2.3781, -2.1994],\n",
      "         [-2.2767, -2.3844, -2.6078, -2.0462, -2.1478, -2.1991, -2.1006,\n",
      "          -2.0400, -2.1015],\n",
      "         [-2.0896, -2.0917, -2.1749, -1.8526, -2.4574, -2.2908, -2.4169,\n",
      "          -2.3378, -2.2095],\n",
      "         [-1.9802, -2.6191, -2.4525, -2.0297, -2.3375, -2.1846, -2.0869,\n",
      "          -1.9867, -2.2894],\n",
      "         [-2.0070, -1.9426, -2.1442, -1.9785, -2.4619, -2.2423, -2.5637,\n",
      "          -2.2778, -2.3453],\n",
      "         [-2.0745, -2.0339, -2.3693, -2.0045, -2.3295, -2.3079, -2.3231,\n",
      "          -2.0232, -2.4275],\n",
      "         [-2.1962, -2.1735, -2.1729, -2.2040, -2.2351, -2.1913, -2.2313,\n",
      "          -2.1828, -2.1900],\n",
      "         [-2.1914, -2.1801, -2.1744, -2.2079, -2.2292, -2.1951, -2.2250,\n",
      "          -2.1839, -2.1894]],\n",
      "\n",
      "        [[-2.2126, -2.2531, -2.2936, -2.4284, -1.8647, -2.4414, -2.1301,\n",
      "          -2.5143, -1.8663],\n",
      "         [-2.3193, -2.1801, -1.9530, -2.7425, -2.5823, -2.2008, -2.0103,\n",
      "          -2.1460, -1.9299],\n",
      "         [-2.2476, -2.4034, -2.3123, -2.1989, -2.4426, -2.0403, -2.2891,\n",
      "          -1.9152, -2.0527],\n",
      "         [-2.2357, -1.9849, -2.2553, -1.8932, -2.3147, -2.2424, -2.4538,\n",
      "          -2.2047, -2.3125],\n",
      "         [-2.2581, -2.3174, -2.4346, -2.1889, -2.2350, -2.2025, -2.1299,\n",
      "          -2.0052, -2.0695],\n",
      "         [-2.0185, -2.2679, -2.1659, -1.8287, -2.3389, -2.2938, -2.5350,\n",
      "          -2.2363, -2.2545],\n",
      "         [-2.1064, -2.5776, -2.4069, -2.2356, -2.2956, -2.0514, -2.1339,\n",
      "          -1.9490, -2.1602],\n",
      "         [-2.0845, -1.7377, -2.2625, -2.0779, -2.4626, -2.4026, -2.4529,\n",
      "          -2.2739, -2.2464],\n",
      "         [-2.2521, -2.1819, -2.3382, -1.9628, -2.3689, -2.1767, -2.2717,\n",
      "          -2.0643, -2.2259],\n",
      "         [-2.1905, -2.1716, -2.1815, -2.2295, -2.2168, -2.2010, -2.2239,\n",
      "          -2.1785, -2.1835],\n",
      "         [-2.1887, -2.1826, -2.1813, -2.2233, -2.2160, -2.1992, -2.2194,\n",
      "          -2.1801, -2.1856]],\n",
      "\n",
      "        [[-2.3282, -1.9329, -2.1961, -2.2857, -1.9252, -2.4155, -2.1046,\n",
      "          -2.5180, -2.2333],\n",
      "         [-2.2035, -2.5966, -1.8382, -2.3831, -2.3753, -2.2147, -2.1550,\n",
      "          -2.2224, -1.9858],\n",
      "         [-2.1863, -2.2879, -2.3430, -2.1216, -2.3145, -2.3539, -2.3361,\n",
      "          -1.9385, -1.9961],\n",
      "         [-2.1116, -2.0542, -2.2194, -1.8787, -2.4842, -2.1378, -2.5442,\n",
      "          -2.2280, -2.2857],\n",
      "         [-2.0948, -2.4754, -2.2970, -2.0723, -2.3200, -2.2259, -2.1307,\n",
      "          -2.0293, -2.2082],\n",
      "         [-2.0159, -1.8749, -2.3381, -1.8599, -2.5209, -2.3293, -2.6090,\n",
      "          -2.2763, -2.2329],\n",
      "         [-2.2068, -2.2290, -2.1986, -2.1922, -2.1105, -2.0544, -2.1785,\n",
      "          -2.2682, -2.3684],\n",
      "         [-1.9133, -1.8370, -2.3278, -1.7759, -2.5774, -2.3452, -2.4624,\n",
      "          -2.5655, -2.3820],\n",
      "         [-2.1523, -2.2409, -2.2847, -2.0215, -2.2023, -2.3019, -2.0050,\n",
      "          -2.3893, -2.2425],\n",
      "         [-2.1079, -2.0707, -2.0300, -1.8576, -2.4003, -2.4362, -2.4837,\n",
      "          -2.3457, -2.2290],\n",
      "         [-2.1871, -2.0805, -2.2605, -2.1128, -2.4353, -2.2203, -2.3534,\n",
      "          -1.9146, -2.3115]],\n",
      "\n",
      "        [[-2.0817, -2.0763, -2.4239, -2.4393, -1.9494, -2.1979, -2.5265,\n",
      "          -2.3567, -1.9241],\n",
      "         [-2.3087, -2.3327, -1.8789, -2.3814, -2.5235, -2.1745, -1.9402,\n",
      "          -2.5102, -1.9689],\n",
      "         [-2.3374, -2.4319, -2.3536, -2.2710, -2.2684, -2.2496, -2.0570,\n",
      "          -1.8452, -2.0991],\n",
      "         [-1.9532, -1.9773, -2.1210, -1.9983, -2.3388, -2.3553, -2.4469,\n",
      "          -2.3270, -2.4213],\n",
      "         [-2.2795, -2.4468, -2.3224, -2.1230, -2.3456, -2.1878, -1.9982,\n",
      "          -2.0003, -2.1667],\n",
      "         [-2.0436, -2.1409, -2.3001, -1.9704, -2.3110, -2.3483, -2.5109,\n",
      "          -2.0313, -2.2427],\n",
      "         [-2.2603, -2.2946, -2.3813, -2.0741, -2.4176, -2.1429, -2.0756,\n",
      "          -1.9853, -2.2302],\n",
      "         [-2.0614, -1.8070, -2.3168, -2.0537, -2.4244, -2.4302, -2.4087,\n",
      "          -2.4079, -2.0775],\n",
      "         [-2.3555, -2.3694, -2.3231, -2.2017, -2.3645, -2.0589, -2.0637,\n",
      "          -1.9237, -2.2220],\n",
      "         [-1.9749, -2.0178, -2.2644, -1.9003, -2.3481, -2.2657, -2.3992,\n",
      "          -2.4090, -2.3554],\n",
      "         [-2.2049, -2.2573, -2.3078, -2.1421, -2.2562, -2.2712, -2.0995,\n",
      "          -2.0455, -2.2216]]], device='cuda:0', grad_fn=<TransposeBackward0>) (tensor([0.]), tensor([0.]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chang/multimodal_neural_gsCAN/seq2seq/seq2seq_model.py:121: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  memory_lengths = torch.tensor(memory_lengths, dtype=torch.long, device=device)\n"
     ]
    }
   ],
   "source": [
    "for (input_batch, input_lengths, _, situation_batch, _, target_batch, target_lengths, agent_positions, target_positions) in training_set.get_data_iterator(batch_size=10):\n",
    "    target_scores, target_position_scores = model(commands_input=input_batch, commands_lengths=input_lengths,\n",
    "                                                          situations_input=situation_batch, target_batch=target_batch,\n",
    "                                                          target_lengths=target_lengths)\n",
    "    print(target_scores, target_position_scores)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.sample(F.log_softmax(target_scores, dim=-1).max(dim=-1)[1].detach()[:,:6], \n",
    "             commands_input=input_batch,\n",
    "             commands_lengths=input_lengths,\n",
    "             situations_input=situation_batch, \n",
    "             target_batch=target_batch,\n",
    "             sos_idx=testing_set.target_vocabulary.sos_idx, eos_idx=testing_set.target_vocabulary.eos_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 11, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 4, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 2, 8, 8, 8, 8, 8, 2, 1, 0, 8, 3, 4, 2, 0, 8, 3, 4, 8, 4, 8,\n",
       "        2, 8, 2, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 5, 8, 8, 2, 8, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 8, 3, 8, 8, 2, 8, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 4, 5, 8, 8, 8, 8, 3, 4, 8, 2, 8, 2, 8, 2, 0, 2, 6, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 5, 8, 3, 8, 8, 8, 2, 8, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 4, 2, 8, 8, 3, 8, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 5, 8, 8, 2, 8, 5, 8, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 5, 8, 4, 8, 8, 8, 7, 3, 5, 8, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 4, 5, 8, 8, 8, 8, 2, 8, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(samples).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'szie'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-de9c95b70533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mszie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'szie'"
     ]
    }
   ],
   "source": [
    "F.log_softmax(target_scores, dim=-1).max(dim=-1)[1].detach().chunk(11, dim=1)[1:].szie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 4, 8, 8, 8, 8, 5, 8, 2, 0, 8, 8, 2, 8, 2, 1, 0, 8, 3, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 2, 8, 8, 8, 8, 8, 3, 5, 3, 4, 2, 8, 4, 8, 2, 8, 4, 8, 2, 6,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 5, 8, 8, 2, 8, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 8, 3, 8, 8, 8, 2, 2, 8, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 4, 5, 8, 8, 8, 8, 3, 8, 8, 3, 4, 5, 3, 2, 6, 2, 8, 1, 0, 8,\n",
       "        2, 1, 0, 8, 2, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 5, 8, 3, 8, 8, 8, 3, 5, 3, 4, 8, 2, 8, 2, 8, 2, 1, 0, 8, 2,\n",
       "        6, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 4, 2, 8, 8, 3, 8, 4, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 5, 8, 8, 2, 8, 2, 8, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 5, 8, 4, 8, 8, 5, 8, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 4, 5, 8, 8, 8, 8, 3, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model.sample(F.log_softmax(target_scores, dim=-1).max(dim=-1)[1].detach()[:,:6], \n",
    "             commands_input=input_batch,\n",
    "             commands_lengths=input_lengths,\n",
    "             situations_input=situation_batch, \n",
    "             target_batch=target_batch,\n",
    "             sos_idx=testing_set.target_vocabulary.sos_idx, eos_idx=testing_set.target_vocabulary.eos_idx)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 4, 5, 2, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 3, 4, 5, 4, 5, 2, 0, 0, 0, 0],\n",
       "        [1, 3, 4, 5, 4, 5, 2, 0, 0, 0, 0],\n",
       "        [1, 3, 4, 5, 4, 5, 2, 0, 0, 0, 0],\n",
       "        [1, 3, 4, 5, 4, 5, 4, 5, 2, 0, 0],\n",
       "        [1, 3, 4, 5, 4, 5, 4, 5, 2, 0, 0],\n",
       "        [1, 3, 4, 5, 4, 5, 4, 5, 2, 0, 0],\n",
       "        [1, 3, 4, 5, 4, 5, 4, 5, 2, 0, 0],\n",
       "        [1, 3, 4, 5, 4, 5, 4, 5, 4, 5, 2],\n",
       "        [1, 3, 4, 5, 4, 5, 4, 5, 4, 5, 2]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[-1.7702, -1.9953, -1.9954, -1.9774, -1.9521, -2.1726, -2.1783, -2.1754,\n",
       "         -2.1732, -2.1720, -2.1714],\n",
       "        [-1.9499, -1.9965, -1.9423, -1.9491, -1.9146, -1.9209, -1.9605, -2.1648,\n",
       "         -2.1753, -2.1814, -2.1796],\n",
       "        [-1.6846, -1.9704, -1.7049, -1.8677, -2.0024, -1.9253, -1.8574, -2.1740,\n",
       "         -2.1812, -2.1766, -2.1727],\n",
       "        [-1.7634, -2.0047, -1.9297, -1.7189, -1.9774, -1.8752, -2.0173, -2.1670,\n",
       "         -2.1744, -2.1758, -2.1734],\n",
       "        [-1.6413, -1.8887, -1.9781, -1.7050, -1.9861, -1.9262, -1.8829, -1.8626,\n",
       "         -1.8369, -2.1745, -2.1835],\n",
       "        [-1.6450, -1.8827, -2.0399, -1.8861, -1.9740, -1.8769, -1.9888, -1.8354,\n",
       "         -2.0403, -2.1730, -2.1838],\n",
       "        [-1.6865, -1.8132, -1.9273, -2.0015, -1.9260, -1.8817, -1.9189, -1.8948,\n",
       "         -1.9843, -2.1673, -2.1733],\n",
       "        [-1.7344, -1.9161, -2.0697, -1.7953, -1.8654, -1.7896, -1.8749, -2.0628,\n",
       "         -1.8690, -2.1618, -2.1725],\n",
       "        [-1.8241, -1.9797, -2.0205, -2.0329, -1.8354, -1.8002, -1.8732, -1.8811,\n",
       "         -2.0080, -1.7668, -1.9296],\n",
       "        [-1.7923, -2.0314, -2.0411, -1.9114, -1.8912, -1.9837, -1.8800, -2.0095,\n",
       "         -1.9736, -1.8409, -1.9879]], device='cuda:0', grad_fn=<MaxBackward0>),\n",
       "indices=tensor([[0, 4, 8, 8, 8, 8, 8, 0, 0, 0, 0],\n",
       "        [0, 2, 8, 8, 8, 8, 0, 2, 2, 2, 0],\n",
       "        [0, 5, 8, 8, 2, 8, 8, 8, 8, 0, 0],\n",
       "        [0, 0, 8, 3, 8, 8, 4, 2, 2, 0, 0],\n",
       "        [0, 4, 5, 8, 8, 8, 8, 8, 8, 2, 2],\n",
       "        [0, 5, 8, 3, 8, 8, 2, 3, 6, 6, 2],\n",
       "        [0, 4, 2, 8, 8, 3, 8, 8, 1, 8, 8],\n",
       "        [0, 5, 8, 8, 2, 8, 8, 6, 6, 8, 8],\n",
       "        [0, 5, 8, 4, 8, 8, 8, 8, 8, 8, 8],\n",
       "        [0, 4, 5, 8, 8, 8, 8, 4, 2, 8, 6]], device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(target_scores, dim=-1).max(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_func(pred):\n",
    "    return 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollout.get_reward(target_scores, 16, input_batch, input_lengths, situation_batch, target_batch, testing_set.target_vocabulary.sos_idx, testing_set.target_vocabulary.eos_idx, reward_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsCAN",
   "language": "python",
   "name": "gscan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
